{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "forest.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sak1b0/proteiNN/blob/master/forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uhMU-BH1HBT",
        "colab_type": "code",
        "outputId": "29e3a549-e7b9-4920-80d3-e867e5d66207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11073
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras import losses\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import argmax\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "prop = {1:[1.8,-0.17,0.11,0,0.38,-0.21,-1.6,0.42,-0.27,1.12,0.61],\n",
        "18:[-4.5,-0.81,2.58,3.71,-2.57,2.11,12.3,-1.56,1.87,-2.55,0.6],\n",
        "14:[-3.5,-0.42,2.05,3.47,-1.62,0.96,4.8,-1.03,0.81,-0.83,0.06],\n",
        "4:[-3.5,-1.23,3.49,2.95,-3.27,1.36,9.2,-0.51,0.81,-0.83,0.46],\n",
        "3:[2.5,0.24,-0.13,0.49,-0.3,-6.04,-2,0.84,-1.05,0.59,1.07],\n",
        "17:[-3.5,-0.58,2.36,3.01,-1.84,1.52,4.1,-0.96,1.1,-0.78,0],\n",
        "5:[-3.5,-2.02,2.68,1.64,-2.9,2.3,8.2,-0.37,1.17,-0.92,0.47],\n",
        "7:[-0.4,-0.01,0.74,1.72,-0.19,0,-1,0,-0.16,1.2,0.07],\n",
        "8:[-3.2,-0.96,2.06,4.76,-1.44,-1.23,3,-2.28,0.28,-0.93,0.61],\n",
        "9:[4.5,0.31,-0.6,-1.56,1.97,-4.81,-3.1,1.81,-0.77,1.16,2.22],\n",
        "12:[3.8,0.56,-0.55,-1.81,1.82,-4.68,-2.8,1.8,-1.1,1.18,1.53],\n",
        "11:[-3.9,-0.99,2.71,5.39,-3.46,3.88,8.8,-2.03,1.7,-0.8,1.15],\n",
        "13:[1.9,0.23,-0.1,-0.76,1.4,-3.66,-3.4,1.18,-0.73,0.55,1.18],\n",
        "6:[2.8,1.13,-0.32,-2.2,1.98,-4.65,-3.7,1.74,-1.43,0.67,2.02],\n",
        "16:[-1.6,-0.45,2.23,-1.52,-1.44,0.75,0.2,0.86,-0.75,0.54,1.95],\n",
        "19:[-0.8,-0.13,0.84,1.83,-0.53,1.74,-0.6,-0.64,0.42,-0.05,0.05],\n",
        "20:[-0.7,-0.14,0.52,1.78,-0.32,0.78,-1.2,-0.26,0.63,-0.02,0.05],\n",
        "23:[-0.9,1.85,0.3,-0.38,1.53,-3.32,-1.9,1.46,-1.57,-0.19,2.65],\n",
        "25:[-1.3,0.94,0.68,-1.09,0.49,-1.01,0.7,0.51,-0.56,-0.23,1.88],\n",
        "22:[4.2,-0.07,-0.31,-0.78,1.46,-3.5,-2.6,1.34,-0.4,1.13,1.32],\n",
        "26:[0,0,0,0,0,0,0,0,0,0,0]}\n",
        "\n",
        "df_train=np.asarray(pd.read_csv('https://raw.githubusercontent.com/sak1b0/proteiNN/master/train_formatted.csv',header=None))\n",
        "df_test=np.asarray(pd.read_csv('https://raw.githubusercontent.com/sak1b0/proteiNN/master/test_formatted.csv',header=None))\n",
        "\n",
        "x_train = df_train[:,0]\n",
        "y_train = df_train[:,1]\n",
        "\n",
        "x_test = df_test[:,0]\n",
        "y_test = df_test[:,1]\n",
        "\n",
        "def debug_me():\n",
        "  #print('train dataframe: ',df_train.shape)\n",
        "  print('x_train shape: ',x_train.shape)\n",
        "  print('y_train shape: ',y_train.shape)\n",
        "\n",
        "  #print('test dataframe: ',df_test.shape)\n",
        "  print('x_test shape: ',x_test.shape)\n",
        "  print('y_test shape: ',y_test.shape)\n",
        "\n",
        "max_len=400\n",
        "\n",
        "#================== x_train ===============\n",
        "n = x_train\n",
        "j=-1\n",
        "\n",
        "for i in x_train:\n",
        "  j=j+1\n",
        "  if(len(i)>max_len):\n",
        "    n = np.delete(n, j)\n",
        "    j=j-1\n",
        "\n",
        "for item in range (len(n)):\n",
        "  n[item] = n[item]+'Z'*(max_len-len(n[item]))\n",
        "\n",
        "x_train = n\n",
        "\n",
        "#================= y_train =================\n",
        "n = y_train\n",
        "j=-1\n",
        "\n",
        "for i in y_train:\n",
        "  j=j+1\n",
        "  if(len(i)>max_len):\n",
        "    n = np.delete(n, j)\n",
        "    j=j-1\n",
        "\n",
        "for item in range (len(n)):\n",
        "  n[item] = n[item]+'Z'*(max_len-len(n[item]))\n",
        "    \n",
        "y_train = n\n",
        "#=================  x_test ==================\n",
        "n = x_test\n",
        "j=-1\n",
        "\n",
        "for i in x_test:\n",
        "  j=j+1\n",
        "  if(len(i)>max_len):\n",
        "    n = np.delete(n, j)\n",
        "    j=j-1\n",
        "\n",
        "for item in range (len(n)):\n",
        "  n[item] = n[item]+'Z'*(max_len-len(n[item]))\n",
        "\n",
        "x_test = n\n",
        "#=================  y_test ==================\n",
        "n = y_test\n",
        "j=-1\n",
        "\n",
        "for i in y_test:\n",
        "  j=j+1\n",
        "  if(len(i)>max_len):\n",
        "    n = np.delete(n, j)\n",
        "    j=j-1\n",
        "\n",
        "for item in range (len(n)):\n",
        "  n[item] = n[item]+'Z'*(max_len-len(n[item]))\n",
        "\n",
        "y_test = n\n",
        "\n",
        "#============= selected data withing range===========\n",
        "\n",
        "\n",
        "max_len = max([len(i) for i in x_train])\n",
        "#print(max_len)\n",
        "\n",
        "max_len = max([len(i) for i in y_test])\n",
        "#print(max_len)\n",
        "\n",
        "print('starting the preprocessing\\n')\n",
        "start_time = time.time()\n",
        "\n",
        "#==============   Properties Encoded start  ============================\n",
        "\n",
        "# ==========x_train conversion start====\n",
        "s = list(x_train)\n",
        "\n",
        "k = []\n",
        "\n",
        "for i in range(len(s)):\n",
        "  t=[]\n",
        "  for item in range(len(s[i])):\n",
        "    t.append(prop[ord(s[i][item])-64])\n",
        "  k.append(t)\n",
        "\n",
        "\n",
        "x_train = np.array(k)\n",
        "\n",
        "#=========== x_train conversion end ====\n",
        "\n",
        "#=========== x_test conversion start====\n",
        "s = list(x_test)\n",
        "\n",
        "k = []\n",
        "\n",
        "for i in range(len(s)):\n",
        "  t=[]\n",
        "  for item in range(len(s[i])):\n",
        "    t.append(prop[ord(s[i][item])-64])\n",
        "  k.append(t)\n",
        "\n",
        "\n",
        "x_test = np.array(k)\n",
        "\n",
        "#============= x_test conversion end====\n",
        "\n",
        "\n",
        "#==============   Properties Encoded end  ============================\n",
        "\n",
        "\n",
        "\n",
        "#==============   ONE_HOT   ===================================================\n",
        "\n",
        "#======= y_train start========\n",
        "#y_train = y_train[0:3]\n",
        "\n",
        "alphabet = 'CEHXZ'\n",
        "\n",
        "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
        "\n",
        "k = []\n",
        "\n",
        "for i in range(len(y_train)):\n",
        "  integer_encoded = [char_to_int[char] for char in y_train[i]]\n",
        "  \n",
        "  onehot_encoded=list()\n",
        "  for value in integer_encoded:\n",
        "\t  letter = [0 for _ in range(len(alphabet))]\n",
        "\t  letter[value] = 1\n",
        "\t  onehot_encoded.append(letter)\n",
        "  \n",
        "  k.append(onehot_encoded)  \n",
        "\n",
        "y_train = np.array(k)\n",
        "#display(y_train)\n",
        "\n",
        "#======= y_train end========\n",
        "\n",
        "#======= y_test start========\n",
        "#y_train = y_train[0:3]\n",
        "\n",
        "alphabet = 'CEHXZ'\n",
        "\n",
        "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
        "\n",
        "k = []\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  integer_encoded = [char_to_int[char] for char in y_test[i]]\n",
        "  \n",
        "  onehot_encoded=list()\n",
        "  for value in integer_encoded:\n",
        "\t  letter = [0 for _ in range(len(alphabet))]\n",
        "\t  letter[value] = 1\n",
        "\t  onehot_encoded.append(letter)\n",
        "  \n",
        "  k.append(onehot_encoded)  \n",
        "\n",
        "y_test = np.array(k)\n",
        "#display(y_train)\n",
        "\n",
        "#======= y_test end========\n",
        "\n",
        "#==============   ONE_HOT   finish ============================\n",
        "\n",
        "print('ending the preprocessing\\n')\n",
        "finish_time=time.time()\n",
        "print ('Time taken to pre-process: ',round(finish_time - start_time,2),' seconds')\n",
        "\n",
        "#==============   ONE_HOT_INVERSION   =========================================\n",
        " \n",
        "#for i in range(len(y_train[0])):\n",
        "#  inverted = int_to_char[argmax(y_train[0][i])]\n",
        "#  print(inverted)\n",
        "\n",
        "#================ it's time to learn============================\n",
        "debug_me()\n",
        "start_time = time.time()\n",
        "  \n",
        "model=Sequential()\n",
        "\n",
        "model.add(LSTM((5),batch_input_shape=(None,400,11),return_sequences=True,activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "print(model.input_shape)\n",
        "print(model.output_shape)\n",
        "\n",
        "history=model.fit(x_train,y_train,epochs=500,validation_data=(x_test,y_test))\n",
        "\n",
        "finish_time=time.time()\n",
        "print ('Time taken to train: ',round((finish_time - start_time)/60,2),' minutes')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting the preprocessing\n",
            "\n",
            "ending the preprocessing\n",
            "\n",
            "Time taken to pre-process:  7.15  seconds\n",
            "x_train shape:  (4061, 400, 11)\n",
            "y_train shape:  (4061, 400, 5)\n",
            "x_test shape:  (1058, 400, 11)\n",
            "y_test shape:  (1058, 400, 5)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_13 (LSTM)               (None, 400, 5)            340       \n",
            "=================================================================\n",
            "Total params: 340\n",
            "Trainable params: 340\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(None, 400, 11)\n",
            "(None, 400, 5)\n",
            "Train on 4061 samples, validate on 1058 samples\n",
            "Epoch 1/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 2.3136 - acc: 0.6537 - val_loss: 1.9413 - val_acc: 0.7151\n",
            "Epoch 2/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 1.6911 - acc: 0.7074 - val_loss: 1.4924 - val_acc: 0.7290\n",
            "Epoch 3/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 1.3318 - acc: 0.7153 - val_loss: 1.0061 - val_acc: 0.7371\n",
            "Epoch 4/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.9911 - acc: 0.7212 - val_loss: 0.9112 - val_acc: 0.7395\n",
            "Epoch 5/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.9578 - acc: 0.7229 - val_loss: 0.8971 - val_acc: 0.7406\n",
            "Epoch 6/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.9474 - acc: 0.7243 - val_loss: 0.8892 - val_acc: 0.7416\n",
            "Epoch 7/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.9404 - acc: 0.7259 - val_loss: 0.8840 - val_acc: 0.7421\n",
            "Epoch 8/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.9351 - acc: 0.7271 - val_loss: 0.8793 - val_acc: 0.7438\n",
            "Epoch 9/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.9305 - acc: 0.7282 - val_loss: 0.8753 - val_acc: 0.7448\n",
            "Epoch 10/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.9264 - acc: 0.7297 - val_loss: 0.8719 - val_acc: 0.7459\n",
            "Epoch 11/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.9231 - acc: 0.7306 - val_loss: 0.8694 - val_acc: 0.7468\n",
            "Epoch 12/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.9199 - acc: 0.7318 - val_loss: 0.8667 - val_acc: 0.7476\n",
            "Epoch 13/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.9174 - acc: 0.7325 - val_loss: 0.8642 - val_acc: 0.7488\n",
            "Epoch 14/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.9149 - acc: 0.7332 - val_loss: 0.8622 - val_acc: 0.7492\n",
            "Epoch 15/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.9130 - acc: 0.7337 - val_loss: 0.8606 - val_acc: 0.7498\n",
            "Epoch 16/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.9113 - acc: 0.7345 - val_loss: 0.8593 - val_acc: 0.7503\n",
            "Epoch 17/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.9100 - acc: 0.7348 - val_loss: 0.8579 - val_acc: 0.7510\n",
            "Epoch 18/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.9086 - acc: 0.7356 - val_loss: 0.8571 - val_acc: 0.7508\n",
            "Epoch 19/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.9073 - acc: 0.7361 - val_loss: 0.8559 - val_acc: 0.7516\n",
            "Epoch 20/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.9061 - acc: 0.7365 - val_loss: 0.8544 - val_acc: 0.7523\n",
            "Epoch 21/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.9049 - acc: 0.7371 - val_loss: 0.8534 - val_acc: 0.7529\n",
            "Epoch 22/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.9038 - acc: 0.7376 - val_loss: 0.8523 - val_acc: 0.7532\n",
            "Epoch 23/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.9027 - acc: 0.7380 - val_loss: 0.8514 - val_acc: 0.7537\n",
            "Epoch 24/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.9016 - acc: 0.7387 - val_loss: 0.8502 - val_acc: 0.7541\n",
            "Epoch 25/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.9004 - acc: 0.7392 - val_loss: 0.8492 - val_acc: 0.7545\n",
            "Epoch 26/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.8492 - acc: 0.7383 - val_loss: 0.7794 - val_acc: 0.7551\n",
            "Epoch 27/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.8194 - acc: 0.7405 - val_loss: 0.7752 - val_acc: 0.7564\n",
            "Epoch 28/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.8127 - acc: 0.7429 - val_loss: 0.7698 - val_acc: 0.7571\n",
            "Epoch 29/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.8096 - acc: 0.7431 - val_loss: 0.7676 - val_acc: 0.7582\n",
            "Epoch 30/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.8084 - acc: 0.7435 - val_loss: 0.7668 - val_acc: 0.7582\n",
            "Epoch 31/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.8078 - acc: 0.7437 - val_loss: 0.7667 - val_acc: 0.7575\n",
            "Epoch 32/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.8071 - acc: 0.7437 - val_loss: 0.7660 - val_acc: 0.7585\n",
            "Epoch 33/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.8065 - acc: 0.7442 - val_loss: 0.7652 - val_acc: 0.7589\n",
            "Epoch 34/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.8056 - acc: 0.7449 - val_loss: 0.7647 - val_acc: 0.7594\n",
            "Epoch 35/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.8046 - acc: 0.7456 - val_loss: 0.7641 - val_acc: 0.7594\n",
            "Epoch 36/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.8037 - acc: 0.7458 - val_loss: 0.7636 - val_acc: 0.7598\n",
            "Epoch 37/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.8032 - acc: 0.7458 - val_loss: 0.7633 - val_acc: 0.7592\n",
            "Epoch 38/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.8028 - acc: 0.7459 - val_loss: 0.7629 - val_acc: 0.7595\n",
            "Epoch 39/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.7431 - acc: 0.7457 - val_loss: 0.5253 - val_acc: 0.7591\n",
            "Epoch 40/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5537 - acc: 0.7456 - val_loss: 0.5225 - val_acc: 0.7592\n",
            "Epoch 41/500\n",
            "4061/4061 [==============================] - 82s 20ms/step - loss: 0.5517 - acc: 0.7460 - val_loss: 0.5216 - val_acc: 0.7598\n",
            "Epoch 42/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5507 - acc: 0.7462 - val_loss: 0.5204 - val_acc: 0.7600\n",
            "Epoch 43/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5499 - acc: 0.7466 - val_loss: 0.5199 - val_acc: 0.7598\n",
            "Epoch 44/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5494 - acc: 0.7466 - val_loss: 0.5195 - val_acc: 0.7605\n",
            "Epoch 45/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5488 - acc: 0.7468 - val_loss: 0.5187 - val_acc: 0.7607\n",
            "Epoch 46/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5482 - acc: 0.7471 - val_loss: 0.5189 - val_acc: 0.7601\n",
            "Epoch 47/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5479 - acc: 0.7471 - val_loss: 0.5181 - val_acc: 0.7606\n",
            "Epoch 48/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5473 - acc: 0.7475 - val_loss: 0.5187 - val_acc: 0.7592\n",
            "Epoch 49/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5472 - acc: 0.7474 - val_loss: 0.5177 - val_acc: 0.7604\n",
            "Epoch 50/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5465 - acc: 0.7477 - val_loss: 0.5168 - val_acc: 0.7610\n",
            "Epoch 51/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5463 - acc: 0.7476 - val_loss: 0.5167 - val_acc: 0.7609\n",
            "Epoch 52/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5459 - acc: 0.7477 - val_loss: 0.5163 - val_acc: 0.7616\n",
            "Epoch 53/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5456 - acc: 0.7478 - val_loss: 0.5161 - val_acc: 0.7616\n",
            "Epoch 54/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5453 - acc: 0.7478 - val_loss: 0.5155 - val_acc: 0.7616\n",
            "Epoch 55/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5449 - acc: 0.7481 - val_loss: 0.5154 - val_acc: 0.7618\n",
            "Epoch 56/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5447 - acc: 0.7479 - val_loss: 0.5154 - val_acc: 0.7620\n",
            "Epoch 57/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5443 - acc: 0.7483 - val_loss: 0.5151 - val_acc: 0.7618\n",
            "Epoch 58/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5441 - acc: 0.7484 - val_loss: 0.5150 - val_acc: 0.7614\n",
            "Epoch 59/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5439 - acc: 0.7483 - val_loss: 0.5145 - val_acc: 0.7615\n",
            "Epoch 60/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5438 - acc: 0.7484 - val_loss: 0.5144 - val_acc: 0.7620\n",
            "Epoch 61/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5435 - acc: 0.7485 - val_loss: 0.5142 - val_acc: 0.7623\n",
            "Epoch 62/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5432 - acc: 0.7486 - val_loss: 0.5142 - val_acc: 0.7615\n",
            "Epoch 63/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5429 - acc: 0.7487 - val_loss: 0.5138 - val_acc: 0.7623\n",
            "Epoch 64/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5428 - acc: 0.7488 - val_loss: 0.5136 - val_acc: 0.7625\n",
            "Epoch 65/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5426 - acc: 0.7489 - val_loss: 0.5135 - val_acc: 0.7626\n",
            "Epoch 66/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5423 - acc: 0.7490 - val_loss: 0.5134 - val_acc: 0.7628\n",
            "Epoch 67/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5420 - acc: 0.7492 - val_loss: 0.5139 - val_acc: 0.7620\n",
            "Epoch 68/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5421 - acc: 0.7491 - val_loss: 0.5130 - val_acc: 0.7629\n",
            "Epoch 69/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5419 - acc: 0.7493 - val_loss: 0.5134 - val_acc: 0.7618\n",
            "Epoch 70/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5417 - acc: 0.7494 - val_loss: 0.5127 - val_acc: 0.7628\n",
            "Epoch 71/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5413 - acc: 0.7499 - val_loss: 0.5123 - val_acc: 0.7629\n",
            "Epoch 72/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5412 - acc: 0.7497 - val_loss: 0.5122 - val_acc: 0.7629\n",
            "Epoch 73/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5409 - acc: 0.7500 - val_loss: 0.5120 - val_acc: 0.7632\n",
            "Epoch 74/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5407 - acc: 0.7499 - val_loss: 0.5117 - val_acc: 0.7632\n",
            "Epoch 75/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5407 - acc: 0.7499 - val_loss: 0.5122 - val_acc: 0.7632\n",
            "Epoch 76/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5403 - acc: 0.7504 - val_loss: 0.5117 - val_acc: 0.7634\n",
            "Epoch 77/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5401 - acc: 0.7502 - val_loss: 0.5118 - val_acc: 0.7637\n",
            "Epoch 78/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5400 - acc: 0.7505 - val_loss: 0.5115 - val_acc: 0.7634\n",
            "Epoch 79/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5397 - acc: 0.7505 - val_loss: 0.5112 - val_acc: 0.7636\n",
            "Epoch 80/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5395 - acc: 0.7506 - val_loss: 0.5108 - val_acc: 0.7639\n",
            "Epoch 81/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5392 - acc: 0.7508 - val_loss: 0.5107 - val_acc: 0.7640\n",
            "Epoch 82/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5389 - acc: 0.7510 - val_loss: 0.5104 - val_acc: 0.7641\n",
            "Epoch 83/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5387 - acc: 0.7511 - val_loss: 0.5101 - val_acc: 0.7643\n",
            "Epoch 84/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5386 - acc: 0.7511 - val_loss: 0.5104 - val_acc: 0.7642\n",
            "Epoch 85/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5384 - acc: 0.7513 - val_loss: 0.5096 - val_acc: 0.7648\n",
            "Epoch 86/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5380 - acc: 0.7515 - val_loss: 0.5093 - val_acc: 0.7650\n",
            "Epoch 87/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5375 - acc: 0.7521 - val_loss: 0.5089 - val_acc: 0.7653\n",
            "Epoch 88/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5371 - acc: 0.7521 - val_loss: 0.5090 - val_acc: 0.7651\n",
            "Epoch 89/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5368 - acc: 0.7523 - val_loss: 0.5087 - val_acc: 0.7649\n",
            "Epoch 90/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5368 - acc: 0.7524 - val_loss: 0.5089 - val_acc: 0.7649\n",
            "Epoch 91/500\n",
            "4061/4061 [==============================] - 82s 20ms/step - loss: 0.5362 - acc: 0.7527 - val_loss: 0.5082 - val_acc: 0.7655\n",
            "Epoch 92/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5361 - acc: 0.7528 - val_loss: 0.5080 - val_acc: 0.7661\n",
            "Epoch 93/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5357 - acc: 0.7531 - val_loss: 0.5078 - val_acc: 0.7655\n",
            "Epoch 94/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5356 - acc: 0.7532 - val_loss: 0.5074 - val_acc: 0.7664\n",
            "Epoch 95/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5353 - acc: 0.7533 - val_loss: 0.5083 - val_acc: 0.7658\n",
            "Epoch 96/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5350 - acc: 0.7537 - val_loss: 0.5073 - val_acc: 0.7661\n",
            "Epoch 97/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5347 - acc: 0.7538 - val_loss: 0.5064 - val_acc: 0.7665\n",
            "Epoch 98/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5345 - acc: 0.7540 - val_loss: 0.5070 - val_acc: 0.7659\n",
            "Epoch 99/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5343 - acc: 0.7542 - val_loss: 0.5079 - val_acc: 0.7650\n",
            "Epoch 100/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5344 - acc: 0.7542 - val_loss: 0.5075 - val_acc: 0.7660\n",
            "Epoch 101/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5338 - acc: 0.7547 - val_loss: 0.5058 - val_acc: 0.7672\n",
            "Epoch 102/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5336 - acc: 0.7549 - val_loss: 0.5064 - val_acc: 0.7663\n",
            "Epoch 103/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5336 - acc: 0.7547 - val_loss: 0.5055 - val_acc: 0.7672\n",
            "Epoch 104/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5332 - acc: 0.7549 - val_loss: 0.5053 - val_acc: 0.7675\n",
            "Epoch 105/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5331 - acc: 0.7550 - val_loss: 0.5053 - val_acc: 0.7673\n",
            "Epoch 106/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5328 - acc: 0.7554 - val_loss: 0.5058 - val_acc: 0.7674\n",
            "Epoch 107/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5326 - acc: 0.7552 - val_loss: 0.5053 - val_acc: 0.7675\n",
            "Epoch 108/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5324 - acc: 0.7556 - val_loss: 0.5046 - val_acc: 0.7680\n",
            "Epoch 109/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5325 - acc: 0.7554 - val_loss: 0.5046 - val_acc: 0.7678\n",
            "Epoch 110/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5320 - acc: 0.7559 - val_loss: 0.5044 - val_acc: 0.7679\n",
            "Epoch 111/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5318 - acc: 0.7559 - val_loss: 0.5041 - val_acc: 0.7678\n",
            "Epoch 112/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5319 - acc: 0.7557 - val_loss: 0.5041 - val_acc: 0.7682\n",
            "Epoch 113/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5317 - acc: 0.7561 - val_loss: 0.5175 - val_acc: 0.7609\n",
            "Epoch 114/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5333 - acc: 0.7551 - val_loss: 0.5039 - val_acc: 0.7682\n",
            "Epoch 115/500\n",
            "4061/4061 [==============================] - 82s 20ms/step - loss: 0.5315 - acc: 0.7561 - val_loss: 0.5035 - val_acc: 0.7684\n",
            "Epoch 116/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5313 - acc: 0.7561 - val_loss: 0.5037 - val_acc: 0.7681\n",
            "Epoch 117/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5308 - acc: 0.7564 - val_loss: 0.5032 - val_acc: 0.7685\n",
            "Epoch 118/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5306 - acc: 0.7567 - val_loss: 0.5032 - val_acc: 0.7683\n",
            "Epoch 119/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5309 - acc: 0.7566 - val_loss: 0.5035 - val_acc: 0.7685\n",
            "Epoch 120/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5306 - acc: 0.7567 - val_loss: 0.5031 - val_acc: 0.7689\n",
            "Epoch 121/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5308 - acc: 0.7565 - val_loss: 0.5031 - val_acc: 0.7683\n",
            "Epoch 122/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5302 - acc: 0.7568 - val_loss: 0.5029 - val_acc: 0.7687\n",
            "Epoch 123/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5306 - acc: 0.7564 - val_loss: 0.5027 - val_acc: 0.7686\n",
            "Epoch 124/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5300 - acc: 0.7570 - val_loss: 0.5028 - val_acc: 0.7690\n",
            "Epoch 125/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5299 - acc: 0.7572 - val_loss: 0.5022 - val_acc: 0.7692\n",
            "Epoch 126/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5302 - acc: 0.7570 - val_loss: 0.5023 - val_acc: 0.7692\n",
            "Epoch 127/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5297 - acc: 0.7573 - val_loss: 0.5021 - val_acc: 0.7691\n",
            "Epoch 128/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5296 - acc: 0.7575 - val_loss: 0.5031 - val_acc: 0.7688\n",
            "Epoch 129/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5296 - acc: 0.7574 - val_loss: 0.5021 - val_acc: 0.7695\n",
            "Epoch 130/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5307 - acc: 0.7568 - val_loss: 0.5020 - val_acc: 0.7692\n",
            "Epoch 131/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5292 - acc: 0.7578 - val_loss: 0.5017 - val_acc: 0.7698\n",
            "Epoch 132/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5291 - acc: 0.7577 - val_loss: 0.5014 - val_acc: 0.7698\n",
            "Epoch 133/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5292 - acc: 0.7576 - val_loss: 0.5015 - val_acc: 0.7698\n",
            "Epoch 134/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5291 - acc: 0.7581 - val_loss: 0.5018 - val_acc: 0.7700\n",
            "Epoch 135/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5289 - acc: 0.7582 - val_loss: 0.5013 - val_acc: 0.7698\n",
            "Epoch 136/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5288 - acc: 0.7584 - val_loss: 0.5017 - val_acc: 0.7700\n",
            "Epoch 137/500\n",
            "4061/4061 [==============================] - 82s 20ms/step - loss: 0.5287 - acc: 0.7585 - val_loss: 0.5015 - val_acc: 0.7700\n",
            "Epoch 138/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5286 - acc: 0.7585 - val_loss: 0.5010 - val_acc: 0.7703\n",
            "Epoch 139/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5288 - acc: 0.7582 - val_loss: 0.5016 - val_acc: 0.7700\n",
            "Epoch 140/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5284 - acc: 0.7587 - val_loss: 0.5010 - val_acc: 0.7704\n",
            "Epoch 141/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5284 - acc: 0.7586 - val_loss: 0.5013 - val_acc: 0.7707\n",
            "Epoch 142/500\n",
            "4061/4061 [==============================] - 82s 20ms/step - loss: 0.5286 - acc: 0.7585 - val_loss: 0.5026 - val_acc: 0.7696\n",
            "Epoch 143/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5282 - acc: 0.7588 - val_loss: 0.5004 - val_acc: 0.7707\n",
            "Epoch 144/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5279 - acc: 0.7588 - val_loss: 0.5005 - val_acc: 0.7704\n",
            "Epoch 145/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5280 - acc: 0.7587 - val_loss: 0.5004 - val_acc: 0.7706\n",
            "Epoch 146/500\n",
            "4061/4061 [==============================] - 82s 20ms/step - loss: 0.5279 - acc: 0.7590 - val_loss: 0.5015 - val_acc: 0.7701\n",
            "Epoch 147/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5277 - acc: 0.7590 - val_loss: 0.5017 - val_acc: 0.7702\n",
            "Epoch 148/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5275 - acc: 0.7592 - val_loss: 0.5005 - val_acc: 0.7708\n",
            "Epoch 149/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5274 - acc: 0.7592 - val_loss: 0.5014 - val_acc: 0.7705\n",
            "Epoch 150/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5273 - acc: 0.7594 - val_loss: 0.5003 - val_acc: 0.7709\n",
            "Epoch 151/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5274 - acc: 0.7594 - val_loss: 0.4999 - val_acc: 0.7712\n",
            "Epoch 152/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5272 - acc: 0.7595 - val_loss: 0.4998 - val_acc: 0.7712\n",
            "Epoch 153/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5272 - acc: 0.7595 - val_loss: 0.4997 - val_acc: 0.7714\n",
            "Epoch 154/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5271 - acc: 0.7595 - val_loss: 0.4998 - val_acc: 0.7708\n",
            "Epoch 155/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5277 - acc: 0.7591 - val_loss: 0.5000 - val_acc: 0.7712\n",
            "Epoch 156/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5273 - acc: 0.7593 - val_loss: 0.4996 - val_acc: 0.7713\n",
            "Epoch 157/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5268 - acc: 0.7599 - val_loss: 0.4998 - val_acc: 0.7708\n",
            "Epoch 158/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5269 - acc: 0.7596 - val_loss: 0.5003 - val_acc: 0.7709\n",
            "Epoch 159/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5268 - acc: 0.7599 - val_loss: 0.4994 - val_acc: 0.7718\n",
            "Epoch 160/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5267 - acc: 0.7599 - val_loss: 0.4996 - val_acc: 0.7714\n",
            "Epoch 161/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5265 - acc: 0.7602 - val_loss: 0.4991 - val_acc: 0.7716\n",
            "Epoch 162/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5267 - acc: 0.7599 - val_loss: 0.5020 - val_acc: 0.7694\n",
            "Epoch 163/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5266 - acc: 0.7600 - val_loss: 0.4989 - val_acc: 0.7718\n",
            "Epoch 164/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5263 - acc: 0.7604 - val_loss: 0.4993 - val_acc: 0.7717\n",
            "Epoch 165/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5262 - acc: 0.7603 - val_loss: 0.4992 - val_acc: 0.7716\n",
            "Epoch 166/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5264 - acc: 0.7599 - val_loss: 0.4992 - val_acc: 0.7718\n",
            "Epoch 167/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5262 - acc: 0.7602 - val_loss: 0.4990 - val_acc: 0.7718\n",
            "Epoch 168/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5319 - acc: 0.7564 - val_loss: 0.5015 - val_acc: 0.7699\n",
            "Epoch 169/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5278 - acc: 0.7592 - val_loss: 0.4994 - val_acc: 0.7715\n",
            "Epoch 170/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5267 - acc: 0.7601 - val_loss: 0.5001 - val_acc: 0.7714\n",
            "Epoch 171/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5264 - acc: 0.7603 - val_loss: 0.4990 - val_acc: 0.7717\n",
            "Epoch 172/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5261 - acc: 0.7604 - val_loss: 0.4986 - val_acc: 0.7717\n",
            "Epoch 173/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5261 - acc: 0.7604 - val_loss: 0.5007 - val_acc: 0.7712\n",
            "Epoch 174/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5260 - acc: 0.7605 - val_loss: 0.4986 - val_acc: 0.7721\n",
            "Epoch 175/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5260 - acc: 0.7605 - val_loss: 0.4994 - val_acc: 0.7719\n",
            "Epoch 176/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5258 - acc: 0.7605 - val_loss: 0.4989 - val_acc: 0.7723\n",
            "Epoch 177/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5263 - acc: 0.7603 - val_loss: 0.4996 - val_acc: 0.7719\n",
            "Epoch 178/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5260 - acc: 0.7606 - val_loss: 0.4993 - val_acc: 0.7721\n",
            "Epoch 179/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5258 - acc: 0.7608 - val_loss: 0.4983 - val_acc: 0.7722\n",
            "Epoch 180/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5257 - acc: 0.7608 - val_loss: 0.4982 - val_acc: 0.7724\n",
            "Epoch 181/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5256 - acc: 0.7608 - val_loss: 0.4982 - val_acc: 0.7722\n",
            "Epoch 182/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5256 - acc: 0.7609 - val_loss: 0.4987 - val_acc: 0.7723\n",
            "Epoch 183/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5259 - acc: 0.7607 - val_loss: 0.4984 - val_acc: 0.7724\n",
            "Epoch 184/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5255 - acc: 0.7610 - val_loss: 0.4983 - val_acc: 0.7719\n",
            "Epoch 185/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5256 - acc: 0.7609 - val_loss: 0.4981 - val_acc: 0.7724\n",
            "Epoch 186/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5254 - acc: 0.7610 - val_loss: 0.4986 - val_acc: 0.7724\n",
            "Epoch 187/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5253 - acc: 0.7611 - val_loss: 0.4989 - val_acc: 0.7724\n",
            "Epoch 188/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5254 - acc: 0.7612 - val_loss: 0.4979 - val_acc: 0.7725\n",
            "Epoch 189/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5255 - acc: 0.7610 - val_loss: 0.4982 - val_acc: 0.7725\n",
            "Epoch 190/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5254 - acc: 0.7611 - val_loss: 0.4985 - val_acc: 0.7724\n",
            "Epoch 191/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5254 - acc: 0.7611 - val_loss: 0.4982 - val_acc: 0.7726\n",
            "Epoch 192/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5254 - acc: 0.7611 - val_loss: 0.4982 - val_acc: 0.7726\n",
            "Epoch 193/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5253 - acc: 0.7612 - val_loss: 0.4979 - val_acc: 0.7724\n",
            "Epoch 194/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5251 - acc: 0.7613 - val_loss: 0.4978 - val_acc: 0.7726\n",
            "Epoch 195/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5252 - acc: 0.7612 - val_loss: 0.4986 - val_acc: 0.7723\n",
            "Epoch 196/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5254 - acc: 0.7611 - val_loss: 0.4986 - val_acc: 0.7722\n",
            "Epoch 197/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5250 - acc: 0.7612 - val_loss: 0.4989 - val_acc: 0.7714\n",
            "Epoch 198/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5251 - acc: 0.7612 - val_loss: 0.4981 - val_acc: 0.7720\n",
            "Epoch 199/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5250 - acc: 0.7614 - val_loss: 0.4982 - val_acc: 0.7722\n",
            "Epoch 200/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5251 - acc: 0.7613 - val_loss: 0.4989 - val_acc: 0.7724\n",
            "Epoch 201/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5248 - acc: 0.7614 - val_loss: 0.4976 - val_acc: 0.7728\n",
            "Epoch 202/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5253 - acc: 0.7612 - val_loss: 0.4976 - val_acc: 0.7729\n",
            "Epoch 203/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5246 - acc: 0.7617 - val_loss: 0.4997 - val_acc: 0.7719\n",
            "Epoch 204/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5249 - acc: 0.7614 - val_loss: 0.4979 - val_acc: 0.7726\n",
            "Epoch 205/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5265 - acc: 0.7606 - val_loss: 0.4978 - val_acc: 0.7727\n",
            "Epoch 206/500\n",
            "4061/4061 [==============================] - 77s 19ms/step - loss: 0.5248 - acc: 0.7615 - val_loss: 0.4973 - val_acc: 0.7724\n",
            "Epoch 207/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5246 - acc: 0.7616 - val_loss: 0.4982 - val_acc: 0.7720\n",
            "Epoch 208/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5247 - acc: 0.7615 - val_loss: 0.4988 - val_acc: 0.7725\n",
            "Epoch 209/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5247 - acc: 0.7615 - val_loss: 0.4975 - val_acc: 0.7724\n",
            "Epoch 210/500\n",
            "4061/4061 [==============================] - 86s 21ms/step - loss: 0.5245 - acc: 0.7617 - val_loss: 0.4982 - val_acc: 0.7726\n",
            "Epoch 211/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5315 - acc: 0.7582 - val_loss: 0.4980 - val_acc: 0.7721\n",
            "Epoch 212/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5248 - acc: 0.7615 - val_loss: 0.4972 - val_acc: 0.7728\n",
            "Epoch 213/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5244 - acc: 0.7618 - val_loss: 0.4975 - val_acc: 0.7727\n",
            "Epoch 214/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5244 - acc: 0.7617 - val_loss: 0.4976 - val_acc: 0.7729\n",
            "Epoch 215/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5250 - acc: 0.7614 - val_loss: 0.4969 - val_acc: 0.7730\n",
            "Epoch 216/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5242 - acc: 0.7617 - val_loss: 0.4973 - val_acc: 0.7728\n",
            "Epoch 217/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5243 - acc: 0.7618 - val_loss: 0.4973 - val_acc: 0.7730\n",
            "Epoch 218/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5243 - acc: 0.7618 - val_loss: 0.4970 - val_acc: 0.7731\n",
            "Epoch 219/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5242 - acc: 0.7618 - val_loss: 0.4970 - val_acc: 0.7730\n",
            "Epoch 220/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5241 - acc: 0.7618 - val_loss: 0.4970 - val_acc: 0.7731\n",
            "Epoch 221/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5243 - acc: 0.7618 - val_loss: 0.5003 - val_acc: 0.7714\n",
            "Epoch 222/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5241 - acc: 0.7619 - val_loss: 0.4973 - val_acc: 0.7733\n",
            "Epoch 223/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5241 - acc: 0.7619 - val_loss: 0.4969 - val_acc: 0.7731\n",
            "Epoch 224/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5245 - acc: 0.7617 - val_loss: 0.4983 - val_acc: 0.7726\n",
            "Epoch 225/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5243 - acc: 0.7620 - val_loss: 0.4966 - val_acc: 0.7732\n",
            "Epoch 226/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5256 - acc: 0.7612 - val_loss: 0.5022 - val_acc: 0.7717\n",
            "Epoch 227/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5249 - acc: 0.7615 - val_loss: 0.4966 - val_acc: 0.7733\n",
            "Epoch 228/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5241 - acc: 0.7619 - val_loss: 0.4973 - val_acc: 0.7732\n",
            "Epoch 229/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5240 - acc: 0.7621 - val_loss: 0.4968 - val_acc: 0.7732\n",
            "Epoch 230/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5240 - acc: 0.7621 - val_loss: 0.4966 - val_acc: 0.7733\n",
            "Epoch 231/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5239 - acc: 0.7621 - val_loss: 0.4969 - val_acc: 0.7731\n",
            "Epoch 232/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5239 - acc: 0.7620 - val_loss: 0.4965 - val_acc: 0.7732\n",
            "Epoch 233/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5241 - acc: 0.7619 - val_loss: 0.4972 - val_acc: 0.7731\n",
            "Epoch 234/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5237 - acc: 0.7623 - val_loss: 0.4967 - val_acc: 0.7735\n",
            "Epoch 235/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5239 - acc: 0.7622 - val_loss: 0.4966 - val_acc: 0.7734\n",
            "Epoch 236/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5237 - acc: 0.7623 - val_loss: 0.4970 - val_acc: 0.7732\n",
            "Epoch 237/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5240 - acc: 0.7619 - val_loss: 0.4967 - val_acc: 0.7733\n",
            "Epoch 238/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5237 - acc: 0.7622 - val_loss: 0.4961 - val_acc: 0.7736\n",
            "Epoch 239/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5237 - acc: 0.7624 - val_loss: 0.4971 - val_acc: 0.7734\n",
            "Epoch 240/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5239 - acc: 0.7623 - val_loss: 0.4968 - val_acc: 0.7733\n",
            "Epoch 241/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5235 - acc: 0.7625 - val_loss: 0.4964 - val_acc: 0.7735\n",
            "Epoch 242/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5237 - acc: 0.7623 - val_loss: 0.4968 - val_acc: 0.7736\n",
            "Epoch 243/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5236 - acc: 0.7623 - val_loss: 0.4970 - val_acc: 0.7731\n",
            "Epoch 244/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5241 - acc: 0.7620 - val_loss: 0.4968 - val_acc: 0.7733\n",
            "Epoch 245/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5239 - acc: 0.7622 - val_loss: 0.4961 - val_acc: 0.7737\n",
            "Epoch 246/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5235 - acc: 0.7626 - val_loss: 0.4971 - val_acc: 0.7736\n",
            "Epoch 247/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5235 - acc: 0.7625 - val_loss: 0.4980 - val_acc: 0.7727\n",
            "Epoch 248/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5235 - acc: 0.7625 - val_loss: 0.4962 - val_acc: 0.7733\n",
            "Epoch 249/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5234 - acc: 0.7624 - val_loss: 0.4961 - val_acc: 0.7739\n",
            "Epoch 250/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5235 - acc: 0.7624 - val_loss: 0.4963 - val_acc: 0.7734\n",
            "Epoch 251/500\n",
            "4061/4061 [==============================] - 77s 19ms/step - loss: 0.5236 - acc: 0.7624 - val_loss: 0.4960 - val_acc: 0.7737\n",
            "Epoch 252/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5251 - acc: 0.7615 - val_loss: 0.4994 - val_acc: 0.7729\n",
            "Epoch 253/500\n",
            "4061/4061 [==============================] - 77s 19ms/step - loss: 0.5241 - acc: 0.7621 - val_loss: 0.4963 - val_acc: 0.7734\n",
            "Epoch 254/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5231 - acc: 0.7626 - val_loss: 0.4957 - val_acc: 0.7737\n",
            "Epoch 255/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5232 - acc: 0.7627 - val_loss: 0.4957 - val_acc: 0.7738\n",
            "Epoch 256/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5232 - acc: 0.7627 - val_loss: 0.4958 - val_acc: 0.7739\n",
            "Epoch 257/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5964 - acc: 0.7412 - val_loss: 0.5569 - val_acc: 0.7484\n",
            "Epoch 258/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5717 - acc: 0.7388 - val_loss: 0.5283 - val_acc: 0.7567\n",
            "Epoch 259/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5520 - acc: 0.7451 - val_loss: 0.5143 - val_acc: 0.7628\n",
            "Epoch 260/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5397 - acc: 0.7516 - val_loss: 0.5049 - val_acc: 0.7671\n",
            "Epoch 261/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5328 - acc: 0.7563 - val_loss: 0.5012 - val_acc: 0.7705\n",
            "Epoch 262/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5298 - acc: 0.7587 - val_loss: 0.4995 - val_acc: 0.7718\n",
            "Epoch 263/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5280 - acc: 0.7598 - val_loss: 0.4983 - val_acc: 0.7722\n",
            "Epoch 264/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5269 - acc: 0.7603 - val_loss: 0.4976 - val_acc: 0.7727\n",
            "Epoch 265/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5260 - acc: 0.7606 - val_loss: 0.4972 - val_acc: 0.7726\n",
            "Epoch 266/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5253 - acc: 0.7608 - val_loss: 0.4970 - val_acc: 0.7728\n",
            "Epoch 267/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5247 - acc: 0.7611 - val_loss: 0.4970 - val_acc: 0.7729\n",
            "Epoch 268/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5242 - acc: 0.7615 - val_loss: 0.4964 - val_acc: 0.7732\n",
            "Epoch 269/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5237 - acc: 0.7618 - val_loss: 0.4962 - val_acc: 0.7734\n",
            "Epoch 270/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5234 - acc: 0.7621 - val_loss: 0.4961 - val_acc: 0.7735\n",
            "Epoch 271/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5232 - acc: 0.7622 - val_loss: 0.4960 - val_acc: 0.7735\n",
            "Epoch 272/500\n",
            "4061/4061 [==============================] - 83s 20ms/step - loss: 0.5231 - acc: 0.7623 - val_loss: 0.4960 - val_acc: 0.7736\n",
            "Epoch 273/500\n",
            "4061/4061 [==============================] - 83s 21ms/step - loss: 0.5230 - acc: 0.7623 - val_loss: 0.4963 - val_acc: 0.7734\n",
            "Epoch 274/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5230 - acc: 0.7623 - val_loss: 0.4958 - val_acc: 0.7738\n",
            "Epoch 275/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5229 - acc: 0.7624 - val_loss: 0.4961 - val_acc: 0.7735\n",
            "Epoch 276/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5229 - acc: 0.7624 - val_loss: 0.4957 - val_acc: 0.7738\n",
            "Epoch 277/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5229 - acc: 0.7624 - val_loss: 0.4959 - val_acc: 0.7737\n",
            "Epoch 278/500\n",
            "4061/4061 [==============================] - 78s 19ms/step - loss: 0.5229 - acc: 0.7624 - val_loss: 0.4962 - val_acc: 0.7735\n",
            "Epoch 279/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5229 - acc: 0.7628 - val_loss: 0.4959 - val_acc: 0.7738\n",
            "Epoch 280/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5228 - acc: 0.7628 - val_loss: 0.4956 - val_acc: 0.7738\n",
            "Epoch 281/500\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.5228 - acc: 0.7628 - val_loss: 0.4956 - val_acc: 0.7739\n",
            "Epoch 282/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5227 - acc: 0.7629 - val_loss: 0.4962 - val_acc: 0.7734\n",
            "Epoch 283/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5228 - acc: 0.7630 - val_loss: 0.4961 - val_acc: 0.7736\n",
            "Epoch 284/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5228 - acc: 0.7630 - val_loss: 0.4958 - val_acc: 0.7737\n",
            "Epoch 285/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5227 - acc: 0.7630 - val_loss: 0.4956 - val_acc: 0.7739\n",
            "Epoch 286/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5227 - acc: 0.7629 - val_loss: 0.4965 - val_acc: 0.7736\n",
            "Epoch 287/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5229 - acc: 0.7629 - val_loss: 0.4957 - val_acc: 0.7739\n",
            "Epoch 288/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5227 - acc: 0.7629 - val_loss: 0.4963 - val_acc: 0.7736\n",
            "Epoch 289/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5228 - acc: 0.7629 - val_loss: 0.4962 - val_acc: 0.7736\n",
            "Epoch 290/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5305 - acc: 0.7590 - val_loss: 0.4969 - val_acc: 0.7736\n",
            "Epoch 291/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5233 - acc: 0.7627 - val_loss: 0.4961 - val_acc: 0.7736\n",
            "Epoch 292/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5229 - acc: 0.7628 - val_loss: 0.4956 - val_acc: 0.7737\n",
            "Epoch 293/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5228 - acc: 0.7628 - val_loss: 0.4965 - val_acc: 0.7736\n",
            "Epoch 294/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5227 - acc: 0.7630 - val_loss: 0.4960 - val_acc: 0.7737\n",
            "Epoch 295/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5227 - acc: 0.7629 - val_loss: 0.4955 - val_acc: 0.7738\n",
            "Epoch 296/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5226 - acc: 0.7630 - val_loss: 0.4955 - val_acc: 0.7738\n",
            "Epoch 297/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5226 - acc: 0.7630 - val_loss: 0.4959 - val_acc: 0.7737\n",
            "Epoch 298/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5230 - acc: 0.7629 - val_loss: 0.4960 - val_acc: 0.7748\n",
            "Epoch 299/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5231 - acc: 0.7629 - val_loss: 0.4954 - val_acc: 0.7738\n",
            "Epoch 300/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5227 - acc: 0.7629 - val_loss: 0.4972 - val_acc: 0.7731\n",
            "Epoch 301/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5228 - acc: 0.7629 - val_loss: 0.4961 - val_acc: 0.7739\n",
            "Epoch 302/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5229 - acc: 0.7628 - val_loss: 0.4954 - val_acc: 0.7741\n",
            "Epoch 303/500\n",
            "4061/4061 [==============================] - 83s 20ms/step - loss: 0.5229 - acc: 0.7627 - val_loss: 0.4955 - val_acc: 0.7740\n",
            "Epoch 304/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5227 - acc: 0.7630 - val_loss: 0.4954 - val_acc: 0.7741\n",
            "Epoch 305/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5227 - acc: 0.7629 - val_loss: 0.4958 - val_acc: 0.7739\n",
            "Epoch 306/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5226 - acc: 0.7629 - val_loss: 0.4963 - val_acc: 0.7737\n",
            "Epoch 307/500\n",
            "4061/4061 [==============================] - 82s 20ms/step - loss: 0.5226 - acc: 0.7631 - val_loss: 0.4953 - val_acc: 0.7741\n",
            "Epoch 308/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5227 - acc: 0.7631 - val_loss: 0.4955 - val_acc: 0.7739\n",
            "Epoch 309/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5226 - acc: 0.7631 - val_loss: 0.4955 - val_acc: 0.7741\n",
            "Epoch 310/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5227 - acc: 0.7631 - val_loss: 0.4954 - val_acc: 0.7741\n",
            "Epoch 311/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5228 - acc: 0.7632 - val_loss: 0.4955 - val_acc: 0.7743\n",
            "Epoch 312/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5225 - acc: 0.7632 - val_loss: 0.4952 - val_acc: 0.7743\n",
            "Epoch 313/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5227 - acc: 0.7631 - val_loss: 0.4958 - val_acc: 0.7740\n",
            "Epoch 314/500\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5227 - acc: 0.7630 - val_loss: 0.4958 - val_acc: 0.7740\n",
            "Epoch 315/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5226 - acc: 0.7631 - val_loss: 0.4957 - val_acc: 0.7741\n",
            "Epoch 316/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5227 - acc: 0.7631 - val_loss: 0.4954 - val_acc: 0.7743\n",
            "Epoch 317/500\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 0.5225 - acc: 0.7633 - val_loss: 0.4966 - val_acc: 0.7737\n",
            "Epoch 318/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5227 - acc: 0.7631 - val_loss: 0.4965 - val_acc: 0.7736\n",
            "Epoch 319/500\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5224 - acc: 0.7634 - val_loss: 0.4954 - val_acc: 0.7741\n",
            "Epoch 320/500\n",
            "2976/4061 [====================>.........] - ETA: 18s - loss: 0.5222 - acc: 0.7633"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE5tuzfRS9SK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXOucdnVW4mF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random as rnd\n",
        "row=rnd.randint(1,500)\n",
        "clm=rnd.randint(1,100)\n",
        "\n",
        "display(y_test[row][clm])\n",
        "display(y_pred[row][clm])\n",
        "plt.plot(y_test[row][clm])\n",
        "plt.plot(y_pred[row][clm])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}