{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "forest.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sak1b0/proteiNN/blob/master/forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uhMU-BH1HBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "outputId": "c392ce8b-c81a-48b4-c028-afdb2ab1e027"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras import losses\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import argmax\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "prop = {1:[1.8,-0.17,0.11,0,0.38,-0.21,-1.6,0.42,-0.27,1.12,0.61],\n",
        "18:[-4.5,-0.81,2.58,3.71,-2.57,2.11,12.3,-1.56,1.87,-2.55,0.6],\n",
        "14:[-3.5,-0.42,2.05,3.47,-1.62,0.96,4.8,-1.03,0.81,-0.83,0.06],\n",
        "4:[-3.5,-1.23,3.49,2.95,-3.27,1.36,9.2,-0.51,0.81,-0.83,0.46],\n",
        "3:[2.5,0.24,-0.13,0.49,-0.3,-6.04,-2,0.84,-1.05,0.59,1.07],\n",
        "17:[-3.5,-0.58,2.36,3.01,-1.84,1.52,4.1,-0.96,1.1,-0.78,0],\n",
        "5:[-3.5,-2.02,2.68,1.64,-2.9,2.3,8.2,-0.37,1.17,-0.92,0.47],\n",
        "7:[-0.4,-0.01,0.74,1.72,-0.19,0,-1,0,-0.16,1.2,0.07],\n",
        "8:[-3.2,-0.96,2.06,4.76,-1.44,-1.23,3,-2.28,0.28,-0.93,0.61],\n",
        "9:[4.5,0.31,-0.6,-1.56,1.97,-4.81,-3.1,1.81,-0.77,1.16,2.22],\n",
        "12:[3.8,0.56,-0.55,-1.81,1.82,-4.68,-2.8,1.8,-1.1,1.18,1.53],\n",
        "11:[-3.9,-0.99,2.71,5.39,-3.46,3.88,8.8,-2.03,1.7,-0.8,1.15],\n",
        "13:[1.9,0.23,-0.1,-0.76,1.4,-3.66,-3.4,1.18,-0.73,0.55,1.18],\n",
        "6:[2.8,1.13,-0.32,-2.2,1.98,-4.65,-3.7,1.74,-1.43,0.67,2.02],\n",
        "16:[-1.6,-0.45,2.23,-1.52,-1.44,0.75,0.2,0.86,-0.75,0.54,1.95],\n",
        "19:[-0.8,-0.13,0.84,1.83,-0.53,1.74,-0.6,-0.64,0.42,-0.05,0.05],\n",
        "20:[-0.7,-0.14,0.52,1.78,-0.32,0.78,-1.2,-0.26,0.63,-0.02,0.05],\n",
        "23:[-0.9,1.85,0.3,-0.38,1.53,-3.32,-1.9,1.46,-1.57,-0.19,2.65],\n",
        "25:[-1.3,0.94,0.68,-1.09,0.49,-1.01,0.7,0.51,-0.56,-0.23,1.88],\n",
        "22:[4.2,-0.07,-0.31,-0.78,1.46,-3.5,-2.6,1.34,-0.4,1.13,1.32],\n",
        "26:[0,0,0,0,0,0,0,0,0,0,0]}\n",
        "\n",
        "df_train=np.asarray(pd.read_csv('https://raw.githubusercontent.com/sak1b0/proteiNN/master/train_formatted.csv',header=None))\n",
        "df_test=np.asarray(pd.read_csv('https://raw.githubusercontent.com/sak1b0/proteiNN/master/test_formatted.csv',header=None))\n",
        "\n",
        "x_train = df_train[:,0]\n",
        "y_train = df_train[:,1]\n",
        "\n",
        "x_test = df_test[:,0]\n",
        "y_test = df_test[:,1]\n",
        "\n",
        "def debug_me():\n",
        "  #print('train dataframe: ',df_train.shape)\n",
        "  print('x_train shape: ',x_train.shape)\n",
        "  print('y_train shape: ',y_train.shape)\n",
        "\n",
        "  #print('test dataframe: ',df_test.shape)\n",
        "  print('x_test shape: ',x_test.shape)\n",
        "  print('y_test shape: ',y_test.shape)\n",
        "\n",
        "max_len=400\n",
        "\n",
        "#================== x_train ===============\n",
        "n = x_train\n",
        "j=-1\n",
        "\n",
        "for i in x_train:\n",
        "  j=j+1\n",
        "  if(len(i)>max_len):\n",
        "    n = np.delete(n, j)\n",
        "    j=j-1\n",
        "\n",
        "for item in range (len(n)):\n",
        "  n[item] = n[item]+'Z'*(max_len-len(n[item]))\n",
        "\n",
        "x_train = n\n",
        "\n",
        "#================= y_train =================\n",
        "n = y_train\n",
        "j=-1\n",
        "\n",
        "for i in y_train:\n",
        "  j=j+1\n",
        "  if(len(i)>max_len):\n",
        "    n = np.delete(n, j)\n",
        "    j=j-1\n",
        "\n",
        "for item in range (len(n)):\n",
        "  n[item] = n[item]+'Z'*(max_len-len(n[item]))\n",
        "    \n",
        "y_train = n\n",
        "#=================  x_test ==================\n",
        "n = x_test\n",
        "j=-1\n",
        "\n",
        "for i in x_test:\n",
        "  j=j+1\n",
        "  if(len(i)>max_len):\n",
        "    n = np.delete(n, j)\n",
        "    j=j-1\n",
        "\n",
        "for item in range (len(n)):\n",
        "  n[item] = n[item]+'Z'*(max_len-len(n[item]))\n",
        "\n",
        "x_test = n\n",
        "#=================  y_test ==================\n",
        "n = y_test\n",
        "j=-1\n",
        "\n",
        "for i in y_test:\n",
        "  j=j+1\n",
        "  if(len(i)>max_len):\n",
        "    n = np.delete(n, j)\n",
        "    j=j-1\n",
        "\n",
        "for item in range (len(n)):\n",
        "  n[item] = n[item]+'Z'*(max_len-len(n[item]))\n",
        "\n",
        "y_test = n\n",
        "\n",
        "#============= selected data withing range===========\n",
        "\n",
        "\n",
        "max_len = max([len(i) for i in x_train])\n",
        "#print(max_len)\n",
        "\n",
        "max_len = max([len(i) for i in y_test])\n",
        "#print(max_len)\n",
        "\n",
        "print('starting the preprocessing\\n')\n",
        "start_time = time.time()\n",
        "\n",
        "#==============   Properties Encoded start  ============================\n",
        "\n",
        "# ==========x_train conversion start====\n",
        "s = list(x_train)\n",
        "\n",
        "k = []\n",
        "\n",
        "for i in range(len(s)):\n",
        "  t=[]\n",
        "  for item in range(len(s[i])):\n",
        "    t.append(prop[ord(s[i][item])-64])\n",
        "  k.append(t)\n",
        "\n",
        "\n",
        "x_train = np.array(k)\n",
        "\n",
        "#=========== x_train conversion end ====\n",
        "\n",
        "#=========== x_test conversion start====\n",
        "s = list(x_test)\n",
        "\n",
        "k = []\n",
        "\n",
        "for i in range(len(s)):\n",
        "  t=[]\n",
        "  for item in range(len(s[i])):\n",
        "    t.append(prop[ord(s[i][item])-64])\n",
        "  k.append(t)\n",
        "\n",
        "\n",
        "x_test = np.array(k)\n",
        "\n",
        "#============= x_test conversion end====\n",
        "\n",
        "\n",
        "#==============   Properties Encoded end  ============================\n",
        "\n",
        "\n",
        "\n",
        "#==============   ONE_HOT   ===================================================\n",
        "\n",
        "#======= y_train start========\n",
        "#y_train = y_train[0:3]\n",
        "\n",
        "alphabet = 'CEHXZ'\n",
        "\n",
        "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
        "\n",
        "k = []\n",
        "\n",
        "for i in range(len(y_train)):\n",
        "  integer_encoded = [char_to_int[char] for char in y_train[i]]\n",
        "  \n",
        "  onehot_encoded=list()\n",
        "  for value in integer_encoded:\n",
        "\t  letter = [0 for _ in range(len(alphabet))]\n",
        "\t  letter[value] = 1\n",
        "\t  onehot_encoded.append(letter)\n",
        "  \n",
        "  k.append(onehot_encoded)  \n",
        "\n",
        "y_train = np.array(k)\n",
        "#display(y_train)\n",
        "\n",
        "#======= y_train end========\n",
        "\n",
        "#======= y_test start========\n",
        "#y_train = y_train[0:3]\n",
        "\n",
        "alphabet = 'CEHXZ'\n",
        "\n",
        "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
        "\n",
        "k = []\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  integer_encoded = [char_to_int[char] for char in y_test[i]]\n",
        "  \n",
        "  onehot_encoded=list()\n",
        "  for value in integer_encoded:\n",
        "\t  letter = [0 for _ in range(len(alphabet))]\n",
        "\t  letter[value] = 1\n",
        "\t  onehot_encoded.append(letter)\n",
        "  \n",
        "  k.append(onehot_encoded)  \n",
        "\n",
        "y_test = np.array(k)\n",
        "#display(y_train)\n",
        "\n",
        "#======= y_test end========\n",
        "\n",
        "#==============   ONE_HOT   finish ============================\n",
        "\n",
        "print('ending the preprocessing\\n')\n",
        "finish_time=time.time()\n",
        "print ('Time taken to pre-process: ',round(finish_time - start_time,2),' seconds')\n",
        "\n",
        "#==============   ONE_HOT_INVERSION   =========================================\n",
        " \n",
        "#for i in range(len(y_train[0])):\n",
        "#  inverted = int_to_char[argmax(y_train[0][i])]\n",
        "#  print(inverted)\n",
        "\n",
        "#================ it's time to learn============================\n",
        "debug_me()\n",
        "start_time = time.time()\n",
        "  \n",
        "model=Sequential()\n",
        "\n",
        "model.add(LSTM((5),batch_input_shape=(None,400,11),return_sequences=True,activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "print(model.input_shape)\n",
        "print(model.output_shape)\n",
        "\n",
        "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
        "\n",
        "finish_time=time.time()\n",
        "print ('Time taken to pre-process: ',round((finish_time - start_time)/60,2),' minutes')\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting the preprocessing\n",
            "\n",
            "ending the preprocessing\n",
            "\n",
            "Time taken to pre-process:  7.03  seconds\n",
            "x_train shape:  (4061, 400, 11)\n",
            "y_train shape:  (4061, 400, 5)\n",
            "x_test shape:  (1058, 400, 11)\n",
            "y_test shape:  (1058, 400, 5)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_12 (LSTM)               (None, 400, 5)            340       \n",
            "=================================================================\n",
            "Total params: 340\n",
            "Trainable params: 340\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(None, 400, 11)\n",
            "(None, 400, 5)\n",
            "Train on 4061 samples, validate on 1058 samples\n",
            "Epoch 1/10\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 2.3768 - acc: 0.6347 - val_loss: 2.2016 - val_acc: 0.7223\n",
            "Epoch 2/10\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 2.0992 - acc: 0.7088 - val_loss: 1.9135 - val_acc: 0.7255\n",
            "Epoch 3/10\n",
            "4061/4061 [==============================] - 79s 20ms/step - loss: 1.7546 - acc: 0.7099 - val_loss: 1.5083 - val_acc: 0.7287\n",
            "Epoch 4/10\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 1.4909 - acc: 0.7125 - val_loss: 1.2546 - val_acc: 0.7277\n",
            "Epoch 5/10\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.9410 - acc: 0.7077 - val_loss: 0.5953 - val_acc: 0.7214\n",
            "Epoch 6/10\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.6210 - acc: 0.7101 - val_loss: 0.5799 - val_acc: 0.7297\n",
            "Epoch 7/10\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.6089 - acc: 0.7166 - val_loss: 0.5705 - val_acc: 0.7353\n",
            "Epoch 8/10\n",
            "4061/4061 [==============================] - 79s 19ms/step - loss: 0.6004 - acc: 0.7216 - val_loss: 0.5644 - val_acc: 0.7388\n",
            "Epoch 9/10\n",
            "4061/4061 [==============================] - 80s 20ms/step - loss: 0.5943 - acc: 0.7255 - val_loss: 0.5587 - val_acc: 0.7429\n",
            "Epoch 10/10\n",
            "4061/4061 [==============================] - 81s 20ms/step - loss: 0.5891 - acc: 0.7283 - val_loss: 0.5537 - val_acc: 0.7461\n",
            "Time taken to pre-process:  13.36  minutes\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}